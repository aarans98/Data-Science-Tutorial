{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "Data Pre-Processing.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "c97648da-ca53-8915-43ac-9c56ea0df123",
        "id": "02lNCM7UGw16",
        "colab_type": "text"
      },
      "source": [
        "# Introduction  \n",
        "\n",
        "\n",
        "On April 15, 1912, during her maiden voyage, the widely considered “unsinkable” RMS Titanic sank after colliding with an iceberg. Unfortunately, there weren’t enough lifeboats for everyone onboard, resulting in the death of 1502 out of 2224 passengers and crew.\n",
        "\n",
        "In the Hollywood blockbuster that was modelled on this tragedy, it seemed to be the case that upper-class people, women and children were more likely to survive than others. But did these properties (socio-economic status, sex and age) really influence one's survival chances? \n",
        "\n",
        "Based on data of a subset of 891 passengers on the Titanic, I will make a model that can be used to predict survival of other Titanic passengers. \n",
        "\n",
        "In this challenge, we ask you to build a predictive model that answers the question: “what sorts of people were more likely to survive?” using passenger data (ie name, age, gender, socio-economic class, etc).\n",
        "\n",
        "### Outline\n",
        "\n",
        "- Preprocessing/cleaning of the provided data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hqaDigmPG3H_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5XebsZrkG4oC",
        "colab_type": "text"
      },
      "source": [
        "# Dataset Download:\n",
        "\n",
        "train: https://docs.google.com/spreadsheets/d/1hFOPnxVT9fyT4TFlwuGGbDLfclY43P48UV24PNfAW2M/edit?usp=sharing\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BXzysoNlIzSi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Only for Google Colab users\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "khZD_YG0I05E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "1d71622d-151a-6d1a-6534-39a31704c78b",
        "id": "Zv8Q5pjqGw19",
        "colab_type": "text"
      },
      "source": [
        "### Preprocessing\n",
        "First, let's load the training data to see what we're dealing with. We will import the file to a pandas DataFrame:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "7fa1b512-509b-f047-372e-ba6b6dd849c2",
        "id": "K7ydkpflGw2A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "train_data = pd.read_csv('train.csv')\n",
        "train_data1 = pd.read_csv('train.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ll3CscWtGw2b",
        "colab_type": "code",
        "outputId": "bfb05225-1343-431e-b66e-f80f2bd23b04",
        "colab": {}
      },
      "source": [
        "train_data.info()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 891 entries, 0 to 890\n",
            "Data columns (total 12 columns):\n",
            " #   Column       Non-Null Count  Dtype  \n",
            "---  ------       --------------  -----  \n",
            " 0   PassengerId  891 non-null    int64  \n",
            " 1   Survived     891 non-null    int64  \n",
            " 2   Pclass       891 non-null    int64  \n",
            " 3   Name         891 non-null    object \n",
            " 4   Sex          891 non-null    object \n",
            " 5   Age          714 non-null    float64\n",
            " 6   SibSp        891 non-null    int64  \n",
            " 7   Parch        891 non-null    int64  \n",
            " 8   Ticket       891 non-null    object \n",
            " 9   Fare         891 non-null    float64\n",
            " 10  Cabin        204 non-null    object \n",
            " 11  Embarked     889 non-null    object \n",
            "dtypes: float64(2), int64(5), object(5)\n",
            "memory usage: 83.7+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "cb6ecc2e-8f10-d1c6-169f-8d747a66e05d",
        "id": "t3fXipbSGw2z",
        "colab_type": "text"
      },
      "source": [
        "Now, let's take a look at the first few rows of the DataFrame:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "ef39996e-1c05-2e63-61ca-b28144c01e0a",
        "id": "Onw4XZLjGw20",
        "colab_type": "code",
        "outputId": "f87c0cad-b629-405c-dce6-f790262f0be8",
        "colab": {}
      },
      "source": [
        "train_data.head(3)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Name</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Ticket</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Cabin</th>\n",
              "      <th>Embarked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Braund, Mr. Owen Harris</td>\n",
              "      <td>male</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>A/5 21171</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
              "      <td>female</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>PC 17599</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>C85</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>Heikkinen, Miss. Laina</td>\n",
              "      <td>female</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>STON/O2. 3101282</td>\n",
              "      <td>7.9250</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   PassengerId  Survived  Pclass  \\\n",
              "0            1         0       3   \n",
              "1            2         1       1   \n",
              "2            3         1       3   \n",
              "\n",
              "                                                Name     Sex   Age  SibSp  \\\n",
              "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
              "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
              "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
              "\n",
              "   Parch            Ticket     Fare Cabin Embarked  \n",
              "0      0         A/5 21171   7.2500   NaN        S  \n",
              "1      0          PC 17599  71.2833   C85        C  \n",
              "2      0  STON/O2. 3101282   7.9250   NaN        S  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "31002ed5-0925-d162-b588-6595eacbf68f",
        "id": "DJQTSt77Gw29",
        "colab_type": "text"
      },
      "source": [
        "# A bit about the dataset\n",
        "\n",
        "'Pclass' column contains a number which indicates class of the passenger's ticket:  1 for first class, 2 for second class and 3 for third class. \n",
        "\n",
        "This could function as a proxy for the socio-economic status of the passenger ('upper', 'middle', 'low'). \n",
        "\n",
        "\n",
        "The 'SibSp' column contains the number of siblings + spouses of the passenger also aboard the Titanic;\n",
        "\n",
        "the 'ParCh' column indicates the number of parents + children of the passenger also aboard the Titanic. \n",
        "\n",
        "The 'Ticket' column contains the ticket numbers of passengers (which are not likely to have any predictive power regarding survival);\n",
        "\n",
        "'Cabin' contains the cabin number of the passenger, if he/she had a cabin, and lastly, \n",
        "\n",
        "'Embarked' indicates the port of embarkation of the passenger: **C**herbourg, **Q**ueenstown or **S**outhampton. The meaning of the other columns is clear, I think.\n",
        "\n",
        "Let's check some more info on the DataFrame: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "a8f8c14a-f0ba-54be-1c2e-bdeb83ab38c9",
        "id": "CR702QTyGw2_",
        "colab_type": "code",
        "outputId": "e2b28fcc-0f4c-42cc-c94d-89372ccc48ae",
        "colab": {}
      },
      "source": [
        "train_data.info()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 891 entries, 0 to 890\n",
            "Data columns (total 12 columns):\n",
            " #   Column       Non-Null Count  Dtype  \n",
            "---  ------       --------------  -----  \n",
            " 0   PassengerId  891 non-null    int64  \n",
            " 1   Survived     891 non-null    int64  \n",
            " 2   Pclass       891 non-null    int64  \n",
            " 3   Name         891 non-null    object \n",
            " 4   Sex          891 non-null    object \n",
            " 5   Age          714 non-null    float64\n",
            " 6   SibSp        891 non-null    int64  \n",
            " 7   Parch        891 non-null    int64  \n",
            " 8   Ticket       891 non-null    object \n",
            " 9   Fare         891 non-null    float64\n",
            " 10  Cabin        204 non-null    object \n",
            " 11  Embarked     889 non-null    object \n",
            "dtypes: float64(2), int64(5), object(5)\n",
            "memory usage: 83.7+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "41b720ba-36ea-52f8-4d58-48d5892480c9",
        "id": "PZZbfttwGw3F",
        "colab_type": "text"
      },
      "source": [
        "The DataFrame contains 891 entries in total, with 12 features. Of those 12 features, 10 have non-null values for every entry, and 2 do not: 'Age', which has 714 non-null entries, and 'Cabin', which has only 204 non-null entries (of course, not everyone had a cabin).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sgZBlueLGw3H",
        "colab_type": "text"
      },
      "source": [
        "If you carefully observe the above summary of pandas, there are total 891 rows, Age shows only 714 (means missing), Embarked (2 missing) and Cabin missing a lot as well. Object data types are non-numeric so we have to find a way to encode them to numerical values."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XpOOymKWGw3K",
        "colab_type": "text"
      },
      "source": [
        "# **Dropping Columns which are not useful**\n",
        "\n",
        "Lets try to drop some of the columns which many not contribute much to our machine learning model such as Name, Ticket, Cabin etc."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_isicKnKGw3K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cols = ['Name', 'Ticket', 'Cabin']\n",
        "train_data = train_data.drop(cols, axis=1)\n",
        "train_data1 = train_data1.drop(cols, axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "whuqvB3sGw3X",
        "colab_type": "code",
        "outputId": "8151ca94-c1ea-424b-bc6e-c8e374e7f18a",
        "colab": {}
      },
      "source": [
        "train_data.info()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 891 entries, 0 to 890\n",
            "Data columns (total 9 columns):\n",
            " #   Column       Non-Null Count  Dtype  \n",
            "---  ------       --------------  -----  \n",
            " 0   PassengerId  891 non-null    int64  \n",
            " 1   Survived     891 non-null    int64  \n",
            " 2   Pclass       891 non-null    int64  \n",
            " 3   Sex          891 non-null    object \n",
            " 4   Age          714 non-null    float64\n",
            " 5   SibSp        891 non-null    int64  \n",
            " 6   Parch        891 non-null    int64  \n",
            " 7   Fare         891 non-null    float64\n",
            " 8   Embarked     889 non-null    object \n",
            "dtypes: float64(2), int64(5), object(2)\n",
            "memory usage: 62.8+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lyt6eid2Gw3h",
        "colab_type": "text"
      },
      "source": [
        "# Dropping rows having missing values\n",
        "Next if we want we can drop all rows in the data that has missing values (NaN). You can do it like"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1kBxkfpGw3j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = train_data.dropna()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S4J0-Gf7Gw3n",
        "colab_type": "code",
        "outputId": "6751c401-b026-472b-87d8-b674e411d0a0",
        "colab": {}
      },
      "source": [
        "train_data.info()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 712 entries, 0 to 890\n",
            "Data columns (total 9 columns):\n",
            " #   Column       Non-Null Count  Dtype  \n",
            "---  ------       --------------  -----  \n",
            " 0   PassengerId  712 non-null    int64  \n",
            " 1   Survived     712 non-null    int64  \n",
            " 2   Pclass       712 non-null    int64  \n",
            " 3   Sex          712 non-null    object \n",
            " 4   Age          712 non-null    float64\n",
            " 5   SibSp        712 non-null    int64  \n",
            " 6   Parch        712 non-null    int64  \n",
            " 7   Fare         712 non-null    float64\n",
            " 8   Embarked     712 non-null    object \n",
            "dtypes: float64(2), int64(5), object(2)\n",
            "memory usage: 55.6+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1uX2u_h1Gw3s",
        "colab_type": "text"
      },
      "source": [
        "# Problem with dropping rows having missing values\n",
        "After dropping rows with missing values we find that the dataset is reduced to 712 rows from 891, which means we are wasting data. Machine learning models need data for training to perform well. So we preserve the data and make use of it as much as we can. We will see it later.\n",
        "Creating Dummy Variables\n",
        "Now we convert the Pclass, Sex, Embarked to columns in pandas and drop them after conversion."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s7RqeedvGw3t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dummies = []\n",
        "\n",
        "cols = ['Pclass', 'Sex', 'Embarked']\n",
        "for col in cols:\n",
        "    dummies.append(pd.get_dummies(train_data1[col]))\n",
        "titanic_dummies = pd.concat(dummies, axis=1)    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WjrjxZkDGw3v",
        "colab_type": "text"
      },
      "source": [
        "# And finally we concatenate to the original dataframe column wise\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IoIupLbEGw3v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data1 = pd.concat((train_data1,titanic_dummies), axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hxtN5Q8SGw3z",
        "colab_type": "text"
      },
      "source": [
        "Now that we converted Pclass, Sex, Embarked values into columns, we drop the redundant same columns from the dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lHlAXmEFGw30",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data1 = train_data1.drop(['Pclass', 'Sex', 'Embarked'], axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1fElDwhCGw39",
        "colab_type": "code",
        "outputId": "f1adc863-d54f-4015-a2e5-a7933a61c6a4",
        "colab": {}
      },
      "source": [
        "train_data1.info()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 891 entries, 0 to 890\n",
            "Data columns (total 14 columns):\n",
            " #   Column       Non-Null Count  Dtype  \n",
            "---  ------       --------------  -----  \n",
            " 0   PassengerId  891 non-null    int64  \n",
            " 1   Survived     891 non-null    int64  \n",
            " 2   Age          714 non-null    float64\n",
            " 3   SibSp        891 non-null    int64  \n",
            " 4   Parch        891 non-null    int64  \n",
            " 5   Fare         891 non-null    float64\n",
            " 6   1            891 non-null    uint8  \n",
            " 7   2            891 non-null    uint8  \n",
            " 8   3            891 non-null    uint8  \n",
            " 9   female       891 non-null    uint8  \n",
            " 10  male         891 non-null    uint8  \n",
            " 11  C            891 non-null    uint8  \n",
            " 12  Q            891 non-null    uint8  \n",
            " 13  S            891 non-null    uint8  \n",
            "dtypes: float64(2), int64(4), uint8(8)\n",
            "memory usage: 48.9 KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ziG0NzscGw3_",
        "colab_type": "text"
      },
      "source": [
        "# Taking Care of Missing Data\n",
        "All is good, except age which has lots of missing values. Lets compute a median or interpolate() all the ages and fill those missing age values. Pandas has a interpolate() function that will replace all the missing NaNs to interpolated values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UnAnpOPMGw3_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data1['Age'] = train_data1['Age'].interpolate()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zcLfI8FiGw4E",
        "colab_type": "text"
      },
      "source": [
        "Now lets observe the data columns. Notice age which is interpolated now with imputed new values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2pdNKQlqGw4E",
        "colab_type": "code",
        "outputId": "a89e2323-d47f-4bf1-9467-c04de4616b16",
        "colab": {}
      },
      "source": [
        "train_data1.info()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 891 entries, 0 to 890\n",
            "Data columns (total 14 columns):\n",
            " #   Column       Non-Null Count  Dtype  \n",
            "---  ------       --------------  -----  \n",
            " 0   PassengerId  891 non-null    int64  \n",
            " 1   Survived     891 non-null    int64  \n",
            " 2   Age          891 non-null    float64\n",
            " 3   SibSp        891 non-null    int64  \n",
            " 4   Parch        891 non-null    int64  \n",
            " 5   Fare         891 non-null    float64\n",
            " 6   1            891 non-null    uint8  \n",
            " 7   2            891 non-null    uint8  \n",
            " 8   3            891 non-null    uint8  \n",
            " 9   female       891 non-null    uint8  \n",
            " 10  male         891 non-null    uint8  \n",
            " 11  C            891 non-null    uint8  \n",
            " 12  Q            891 non-null    uint8  \n",
            " 13  S            891 non-null    uint8  \n",
            "dtypes: float64(2), int64(4), uint8(8)\n",
            "memory usage: 48.9 KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ejRq_FaxGw4H",
        "colab_type": "text"
      },
      "source": [
        "# Converting the dataframe to numpy\n",
        "\n",
        "Now that we have converted all the data to numeric, its time for preparing the data for machine learning models. \n",
        "\n",
        "This is where scikit and numpy come into play:\n",
        "X = Input set with 14 attributes\n",
        "y = Small y Output, in this case ‘Survived’\n",
        "Now we convert our dataframe from pandas to numpy and we assign input and output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RPe2HXTvGw4I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = train_data1.values\n",
        "y = train_data1['Survived'].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j3sZH6JLGw4L",
        "colab_type": "text"
      },
      "source": [
        "X has still Survived values in it, which should not be there. So we drop in numpy column which is the 1st column."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2nxXxAhcGw4L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = np.delete(X, 1, axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ePkOfEVXGw4N",
        "colab_type": "text"
      },
      "source": [
        "# Dividing data set into training set and test set\n",
        "Now that we are ready with X and y, lets split the dataset for 70% Training and 30% test set using scikit model_selection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PxGi0V39Gw4N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ycCdJ5_CGw4Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}